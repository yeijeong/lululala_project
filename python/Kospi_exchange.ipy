import urllib.request
from bs4 import BeautifulSoup
from urllib import parse
from datetime import datetime
import datetime
import pandas as pd
import time
import time
import pymysql

def to_dbeaver(DateTime, Kospi, Exchange) :
    conn = pymysql.connect(
        host='localhost'
        , user='root'
        , password='1234'
        , db='lululala_project'
        , charset='utf8'
    )
    cur = conn.cursor()

    sql = "INSERT INTO kospi_exchange VALUES ({}, {}, {})".format("\""+DateTime+"\"", "\""+Kospi+"\"", "\""+Exchange+"\"")
    try : 
        print("Insert Success")
        cur.execute(sql)
    except Exception as e :
        print('Error Message :', e)
        return
    conn.commit()
    conn.close()

# ConnectionError방지
headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'}

def get_kospi_obj(basic_url):
    fp = urllib.request.urlopen(basic_url) # 3시30이 아니면 계속 실행
    source = fp.read()
    fp.close() 

    soup = BeautifulSoup(source, 'html.parser')

    return soup

stoptime = datetime.datetime.now().time()

while True:
    if stoptime.strftime('%p') == 'PM' and stoptime.hour == 3 and stoptime.minute >= 30: # 오후 3시 반 이후인지 확인
        break # 3시 30에 멈추는 코드
    else:
        kospi_info = []
        kospi_url = "https://finance.naver.com/sise/" # 코스피
        soup = get_kospi_obj(kospi_url)
        soup = soup.findAll("span",class_="num")
        kospi_value = soup[1].string #코스피 지수

        #환율 실시간
        exchange_url = "https://finance.naver.com/marketindex/"
        soup = get_kospi_obj(exchange_url)
        soup = soup.findAll("span",class_="value")
        exchange = soup[0].string #미국환율 지수

        now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        to_dbeaver(now, kospi_value, exchange)

        time.sleep(10)